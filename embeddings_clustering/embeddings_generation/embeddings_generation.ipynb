{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings Generation\n",
        "\n",
        "In this part, we generate sentence embeddings to represent text data in a vector space suitable for clustering. The core idea is to transform cleaned 15min.lt news articles and their mBART-generated summaries into numerical vectors that capture their semantic meaning.\n",
        "\n",
        "We use the SentenceTransformer library, which provides powerful pre-trained models based on transformer architectures optimized for semantic similarity and clustering tasks. To generate textual embeddings we are using a pretrained SentenceTransformer model (all-MiniLM-L6-v2). These embeddings convert our textual data into vector representations, enabling effective clustering (Agglomerative Clustering) and visualization (UMAP). The selected model provides a balanced trade-off between computational efficiency and embedding quality."
      ],
      "metadata": {
        "id": "RNdbgXfj63VC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import modules\n",
        "* SentenceTransformer - library for text vectorization (turns texts into numeric vectors)"
      ],
      "metadata": {
        "id": "rx9oX11cqnYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8oDAb8GAkHaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* device = \"cuda\" if torch.cuda.is_available() else \"cpu\" - since the number of summaries in dataset are 2927, it's highly recommended to use GPU\n",
        "* model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" - model that is compatible with Lithuanian language, effective, generates 384 dimensions vectors\n",
        "* texts = df[\"mbart_summary\"].tolist() - converting pandas Series to Python list (needed for SentenceTransformers model)"
      ],
      "metadata": {
        "id": "c6ZUz5sWrj_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device in use: {device}\")\n",
        "\n",
        "df = pd.read_csv(\"/content/mbart_summary_dataset.csv\")\n",
        "\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "model = SentenceTransformer(model_name, device=device)\n",
        "\n",
        "texts = df[\"mbart_summary\"].tolist()"
      ],
      "metadata": {
        "id": "PyNPj7perT8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converts texts into numeric vectors (embeddings) using the SentenceTransformer model\n",
        "* texts - mBART generated summaries\n",
        "* show_progress_bar=True - shows the progress of how many texts are processed\n",
        "* convert_to_numpy=True - converting results to Numpy (not PyTorch tensors) for later use with UMAP\n",
        "* normalize_embeddings=True - ensures that all vectors are of the same scale - for UMAP and clasterization\n",
        "* np.save(\"/content/mbart_embeddings.npy\", embeddings) - saved in .npy format whitch is usefull for clustering and UMAP\n",
        "\n",
        "**After this step, each of our articles is represented as a numerical vector. These vectors will serve as the basis for subsequent clustering and visualization tasks**"
      ],
      "metadata": {
        "id": "Wioo_ocTubN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.encode(\n",
        "    texts,\n",
        "    batch_size=32,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True,\n",
        "    normalize_embeddings=True\n",
        ")\n",
        "\n",
        "# Output summary of generated embeddings: total number and embedding dimension\n",
        "print(f\"Generated {embeddings.shape[0]} embeddings, length of the vector: {embeddings.shape[1]}\")\n",
        "\n",
        "np.save(\"/content/mbart_embeddings.npy\", embeddings)"
      ],
      "metadata": {
        "id": "nRv_yYQJubFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}